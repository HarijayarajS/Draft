// main.rs
use axum::{extract::ws::{WebSocket, WebSocketUpgrade, Message}, extract::Query, routing::get, Router, response::IntoResponse};
use serde::{Deserialize, Serialize};
use serde_json::{Value, json};
use std::{collections::{HashMap, HashSet}, net::SocketAddr, sync::Arc};
use tokio::{sync::mpsc::{UnboundedSender, unbounded_channel}, net::TcpListener};
use dashmap::DashMap;
use tokio_postgres::{NoTls, Error};
use futures_util::{StreamExt, SinkExt};

#[derive(Debug, Deserialize)]
struct ClientParams {
    client_id: String,
}

#[derive(Debug, Deserialize)]
struct ClientMessage {
    action: String,
    filter: Option<HashMap<String, Value>>,
}

type ClientId = String;
type ClientFilters = Arc<DashMap<ClientId, HashMap<String, Value>>>;
type ClientSenders = Arc<DashMap<ClientId, UnboundedSender<Message>>>;

#[tokio::main]
async fn main() -> Result<(), Error> {
    let filters: ClientFilters = Arc::new(DashMap::new());
    let senders: ClientSenders = Arc::new(DashMap::new());

    let filters_clone = filters.clone();
    let senders_clone = senders.clone();

    // Spawn PostgreSQL LISTEN handler
    tokio::spawn(async move {
        listen_to_pg(filters_clone, senders_clone).await.unwrap();
    });

    // Axum router
    let app = Router::new()
        .route("/ws", get(ws_handler))
        .with_state((filters, senders));

    let listener = TcpListener::bind("0.0.0.0:3000").await.unwrap();
    axum::serve(listener, app).await.unwrap();
    Ok(())
}

async fn ws_handler(
    ws: WebSocketUpgrade,
    Query(params): Query<ClientParams>,
    axum::extract::State((filters, senders)): axum::extract::State<(ClientFilters, ClientSenders)>,
) -> impl IntoResponse {
    ws.on_upgrade(move |socket| handle_socket(socket, params.client_id, filters, senders))
}

async fn handle_socket(
    socket: WebSocket,
    client_id: String,
    filters: ClientFilters,
    senders: ClientSenders,
) {
    let (mut ws_sender, mut ws_receiver) = socket.split();
    let (tx, mut rx) = unbounded_channel::<Message>();

    senders.insert(client_id.clone(), tx.clone());

    // Forward task
    tokio::spawn(async move {
        while let Some(msg) = rx.recv().await {
            let _ = ws_sender.send(msg).await;
        }
    });

    while let Some(Ok(Message::Text(text))) = ws_receiver.next().await {
        if let Ok(msg) = serde_json::from_str::<ClientMessage>(&text) {
            if msg.action == "subscribe" {
                if let Some(filter_map) = msg.filter {
                    filters.insert(client_id.clone(), filter_map);
                }
            } else if msg.action == "unsubscribe" {
                filters.remove(&client_id);
            }
        }
    }

    // Cleanup on disconnect
    filters.remove(&client_id);
    senders.remove(&client_id);
}

async fn listen_to_pg(filters: ClientFilters, senders: ClientSenders) -> Result<(), Error> {
    let (client, mut connection) = tokio_postgres::connect("host=localhost user=postgres password=postgres dbname=mydb", NoTls).await?;
    tokio::spawn(async move {
        if let Err(e) = connection.await {
            eprintln!("Connection error: {}", e);
        }
    });

    client.batch_execute("LISTEN lister_updated;").await?;
    let mut listener = client.notifications();

    while let Some(notification) = listener.recv().await {
        let payload = notification.payload();
        let row: Value = serde_json::from_str(payload).unwrap_or_default();
        broadcast_filtered(&filters, &senders, &row);
    }
    Ok(())
}

fn broadcast_filtered(
    filters: &ClientFilters,
    senders: &ClientSenders,
    row: &Value,
) {
    for entry in filters.iter() {
        let client_id = entry.key();
        let filter = entry.value();

        let is_match = filter.iter().all(|(k, v)| {
            row.get(k).map_or(false, |actual| actual == v)
        });

        if is_match {
            if let Some(tx) = senders.get(client_id) {
                let _ = tx.send(Message::Text(json!({
                    "event": "filtered_event",
                    "data": row
                }).to_string()));
            }
        }
    }
}


âœ… Updated your server to support:

ðŸ§  Dynamic WHERE Filters from Client

Clients can now subscribe with multiple fields:

{
  "action": "subscribe",
  "filter": {
    "company_id": 42,
    "category": "cars"
  }
}

Server:

Stores per-client filters in memory

Listens to PostgreSQL changes via NOTIFY

Broadcasts events only to matching clients



---

ðŸš€ Scales to 21K+ Connections

Uses DashMap + unbounded_channel (non-blocking)

Minimal allocation per client

Shared global filter matcher per update



---

ðŸ§ª PostgreSQL Reminder

Use a trigger to notify relevant fields:

PERFORM pg_notify(
  'lister_updated',
  json_build_object(
    'company_id', NEW.company_id,
    'category', NEW.category,
    'title', NEW.title
  )::text
);


---

Would you like help creating:

A quick frontend UI to test this

Rate limiting / throttling

unsubscribe specific filters

Wildcard matching (e.g., any category for company_id = 42)?


